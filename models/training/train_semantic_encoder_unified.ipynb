{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Semantic Symptom Encoder - Unified Training & Comparison\n",
                "\n",
                "This notebook consolidates the Semantic Symptom Encoder training, testing, and model comparison:\n",
                "\n",
                "## Contents\n",
                "1. **Part 1: Embedding Generation** - Compute embeddings for symptom vocabulary\n",
                "2. **Part 2: Testing** - Validate semantic understanding on various symptom phrases\n",
                "3. **Part 3: Model Comparison** - Compare different sentence transformer models\n",
                "\n",
                "**Key Features:**\n",
                "- Zero ML training required - uses pre-trained sentence embeddings\n",
                "- Semantic understanding - \"can't breathe\" ‚âà \"shortness of breath\"\n",
                "- Sentence-level encoding - prevents symptom dilution in long text\n",
                "- Max-pooling - for each symptom, takes best match across sentences\n",
                "\n",
                "**Architecture:**\n",
                "```\n",
                "Free-text input ‚Üí Sentence Transformer ‚Üí Cosine Similarity ‚Üí Top-K Symptoms\n",
                "                  (multi-qa-mpnet)       (vs 480 symptoms)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Project root: c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import json, joblib, warnings, sys, os, time\n",
                "from tqdm import tqdm\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "project_root = Path(os.getcwd()).parent.parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "\n",
                "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
                "\n",
                "print(f\"Project root: {project_root}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 1: Training (Embedding Generation)\n",
                "\n",
                "The semantic encoder doesn't require traditional ML training. Instead, it:\n",
                "1. Loads the symptom vocabulary (480 canonical symptoms)\n",
                "2. Computes embeddings using pre-trained sentence transformer\n",
                "3. Caches embeddings for fast inference"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.1 Check Current Symptom Vocabulary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Symptom vocabulary: 480 symptoms\n",
                        "\n",
                        "First 10 symptoms:\n",
                        "  1. abdominal distention\n",
                        "  2. abdominal pain\n",
                        "  3. abdominal swelling\n",
                        "  4. abnormal appearing skin\n",
                        "  5. abnormal appearing tongue\n",
                        "  6. abnormal breathing sounds\n",
                        "  7. abnormal heart rhythm\n",
                        "  8. abnormal involuntary movements\n",
                        "  9. abnormal movement of eyelid\n",
                        "  10. abnormal size or shape of ear\n",
                        "\n",
                        "Last 10 symptoms:\n",
                        "  471. weight gain\n",
                        "  472. weight loss\n",
                        "  473. wheezing\n",
                        "  474. white discharge from eye\n",
                        "  475. wrinkles on skin\n",
                        "  476. wrist lump or mass\n",
                        "  477. wrist pain\n",
                        "  478. wrist stiffness or tightness\n",
                        "  479. wrist swelling\n",
                        "  480. wrist weakness\n"
                    ]
                }
            ],
            "source": [
                "# Load symptom vocabulary\n",
                "vocab_path = project_root / \"data\" / \"symptom_vocabulary.json\"\n",
                "with open(vocab_path) as f:\n",
                "    symptoms = json.load(f)\n",
                "\n",
                "print(f\"Symptom vocabulary: {len(symptoms)} symptoms\")\n",
                "print(f\"\\nFirst 10 symptoms:\")\n",
                "for i, s in enumerate(symptoms[:10]):\n",
                "    print(f\"  {i+1}. {s}\")\n",
                "\n",
                "print(f\"\\nLast 10 symptoms:\")\n",
                "for i, s in enumerate(symptoms[-10:]):\n",
                "    print(f\"  {len(symptoms)-9+i}. {s}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.2 Check Consistency with Model Features\n",
                "\n",
                "The symptom vocabulary should match the features used to train the disease classifiers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model uses: 480 symptom features\n",
                        "Vocabulary: 480 symptoms\n",
                        "\n",
                        "‚úì Vocabulary matches model features exactly!\n"
                    ]
                }
            ],
            "source": [
                "# Load model feature columns\n",
                "model_cols_path = project_root / \"models\" / \"checkpoints\" / \"symptom_columns.json\"\n",
                "if model_cols_path.exists():\n",
                "    with open(model_cols_path) as f:\n",
                "        model_cols = json.load(f)\n",
                "    \n",
                "    print(f\"Model uses: {len(model_cols)} symptom features\")\n",
                "    print(f\"Vocabulary: {len(symptoms)} symptoms\")\n",
                "    \n",
                "    missing = [s for s in model_cols if s not in symptoms]\n",
                "    extra = [s for s in symptoms if s not in model_cols]\n",
                "    \n",
                "    if missing:\n",
                "        print(f\"\\n‚ö†Ô∏è {len(missing)} symptoms in model but NOT in vocabulary:\")\n",
                "        print(f\"   {missing[:5]}...\")\n",
                "    if extra:\n",
                "        print(f\"\\n‚ö†Ô∏è {len(extra)} symptoms in vocabulary but NOT in model:\")\n",
                "        print(f\"   {extra[:5]}...\")\n",
                "    if not missing and not extra:\n",
                "        print(\"\\n‚úì Vocabulary matches model features exactly!\")\n",
                "else:\n",
                "    print(\"No model checkpoints found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.3 Update Vocabulary (if needed)\n",
                "\n",
                "Run this cell to sync vocabulary with model features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Vocabulary update skipped (set UPDATE_VOCABULARY = True to update)\n"
                    ]
                }
            ],
            "source": [
                "# Uncomment to update vocabulary to match model features\n",
                "# ONLY run this if there are missing symptoms\n",
                "\n",
                "UPDATE_VOCABULARY = False  # Set to True to update\n",
                "\n",
                "if UPDATE_VOCABULARY and model_cols_path.exists():\n",
                "    # Merge vocabularies\n",
                "    updated = sorted(set(symptoms + model_cols))\n",
                "    \n",
                "    # Backup original\n",
                "    backup_path = project_root / \"data\" / \"symptom_vocabulary.json\"\n",
                "    with open(backup_path, 'w') as f:\n",
                "        json.dump(symptoms, f, indent=2)\n",
                "    print(f\"Backed up original to {backup_path.name}\")\n",
                "    \n",
                "    # Save updated\n",
                "    with open(vocab_path, 'w') as f:\n",
                "        json.dump(updated, f, indent=2)\n",
                "    \n",
                "    print(f\"Updated vocabulary: {len(symptoms)} ‚Üí {len(updated)} symptoms\")\n",
                "    symptoms = updated\n",
                "else:\n",
                "    print(\"Vocabulary update skipped (set UPDATE_VOCABULARY = True to update)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.4 Generate Embeddings\n",
                "\n",
                "This is the \"training\" step - computing embeddings for all symptoms.\n",
                "Embeddings are cached to `data/embeddings/semantic_symptom_embeddings.npy`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "No cached embeddings found - will compute on init.\n"
                    ]
                }
            ],
            "source": [
                "from models.architectures.semantic_symptom_encoder import SemanticSymptomEncoder\n",
                "\n",
                "# Check if embeddings exist\n",
                "MODEL_NAME = \"all-MiniLM-L12-v2\"\n",
                "embeddings_path = project_root / \"data\" / \"embeddings\" / f\"semantic_symptom_embeddings_{MODEL_NAME}.npy\"\n",
                "if embeddings_path.exists():\n",
                "    existing = np.load(embeddings_path)\n",
                "    print(f\"Existing embeddings: {existing.shape}\")\n",
                "    if existing.shape[0] != len(symptoms):\n",
                "        print(f\"‚ö†Ô∏è Mismatch! Vocabulary has {len(symptoms)} symptoms but embeddings have {existing.shape[0]}\")\n",
                "        print(\"   Embeddings will be regenerated on encoder init.\")\n",
                "else:\n",
                "    print(\"No cached embeddings found - will compute on init.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading sentence transformer model: all-MiniLM-L12-v2\n",
                        "Loading cached symptom embeddings from c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\embeddings\\semantic_symptom_embeddings_all-MiniLM-L12-v2.npy\n",
                        "Computing symptom embeddings (this is a one-time operation)...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:39<00:00,  2.62s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved symptom embeddings to c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\embeddings\\semantic_symptom_embeddings_all-MiniLM-L12-v2.npy\n",
                        "Semantic Symptom Encoder initialized with 480 symptoms\n",
                        "\n",
                        "‚úì Encoder ready!\n",
                        "  Symptoms: 480\n",
                        "  Embeddings: (480, 384)\n",
                        "  Model: all-MiniLM-L12-v2\n",
                        "  Threshold: 0.45\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Initialize encoder (this computes embeddings if needed)\n",
                "encoder = SemanticSymptomEncoder(\n",
                "    model_name=MODEL_NAME,\n",
                "    similarity_threshold=0.45,\n",
                "    top_k=20\n",
                ")\n",
                "\n",
                "print(f\"\\n‚úì Encoder ready!\")\n",
                "print(f\"  Symptoms: {len(encoder.symptoms)}\")\n",
                "print(f\"  Embeddings: {encoder.symptom_embeddings.shape}\")\n",
                "print(f\"  Model: {encoder.model_name}\")\n",
                "print(f\"  Threshold: {encoder.similarity_threshold}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.5 Force Regenerate Embeddings (Optional)\n",
                "\n",
                "Use this if you've updated the vocabulary or enrichment function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "To force regeneration, uncomment: encoder.regenerate_embeddings()\n"
                    ]
                }
            ],
            "source": [
                "# Uncomment to force regeneration\n",
                "# encoder.regenerate_embeddings()\n",
                "print(\"To force regeneration, uncomment: encoder.regenerate_embeddings()\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 2: Testing\n",
                "\n",
                "Validate that the semantic encoder correctly understands symptom phrases."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.1 Basic Symptom Matching"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing variations of 'headache':\n",
                        "\n",
                        "  'my head is killing me'\n",
                        "    ‚Üí none (0.000)\n",
                        "\n",
                        "  'headache'\n",
                        "    ‚Üí headache (0.461)\n",
                        "\n",
                        "  'I have a terrible headache'\n",
                        "    ‚Üí none (0.000)\n",
                        "\n",
                        "  'pain in my head'\n",
                        "    ‚Üí none (0.000)\n",
                        "\n",
                        "  'migraine'\n",
                        "    ‚Üí none (0.000)\n",
                        "\n",
                        "  'head hurts so bad'\n",
                        "    ‚Üí none (0.000)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "simple_tests = [\n",
                "    \"my head is killing me\",\n",
                "    \"headache\",\n",
                "    \"I have a terrible headache\",\n",
                "    \"pain in my head\",\n",
                "    \"migraine\",\n",
                "    \"head hurts so bad\"\n",
                "]\n",
                "\n",
                "print(\"Testing variations of 'headache':\\n\")\n",
                "for text in simple_tests:\n",
                "    result = encoder.encode_symptoms(text)\n",
                "    top = list(result['confidence_scores'].items())[0] if result['confidence_scores'] else ('none', 0)\n",
                "    print(f\"  '{text}'\")\n",
                "    print(f\"    ‚Üí {top[0]} ({top[1]:.3f})\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.2 Sentence-Level vs Whole-Text Encoding\n",
                "\n",
                "Sentence-level encoding prevents symptom dilution in long paragraphs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "COMPARISON: Sentence-Level vs Whole-Text\n",
                        "============================================================\n",
                        "\n",
                        "üü¢ Sentence-level: 4 symptoms, headache=0.000\n",
                        "    nausea and vomitting: 0.507\n",
                        "    fever: 0.504\n",
                        "    nausea: 0.479\n",
                        "    high fever: 0.472\n",
                        "\n",
                        "üî¥ Whole-text: 2 symptoms, headache=0.000\n",
                        "    diarrhea: 0.471\n",
                        "    nausea and vomitting: 0.468\n",
                        "\n",
                        "‚Üí Sentence-level worse at detecting 'headache'\n"
                    ]
                }
            ],
            "source": [
                "long_text = \"\"\"\n",
                "I've been feeling really unwell for the past few days. I have a terrible headache \n",
                "that won't go away, and I feel nauseous all the time. Yesterday I started throwing up \n",
                "and now I have diarrhea too. My whole body aches and I'm running a fever. \n",
                "I also feel really tired and weak, can barely get out of bed.\n",
                "\"\"\"\n",
                "\n",
                "result_sentence = encoder.encode_symptoms(long_text, use_sentence_level=True)\n",
                "result_whole = encoder.encode_symptoms(long_text, use_sentence_level=False)\n",
                "\n",
                "print(\"COMPARISON: Sentence-Level vs Whole-Text\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "headache_sent = result_sentence['confidence_scores'].get('headache', 0)\n",
                "headache_whole = result_whole['confidence_scores'].get('headache', 0)\n",
                "\n",
                "print(f\"\\nüü¢ Sentence-level: {len(result_sentence['detected_symptoms'])} symptoms, headache={headache_sent:.3f}\")\n",
                "for s, c in list(result_sentence['confidence_scores'].items())[:5]:\n",
                "    print(f\"    {s}: {c:.3f}\")\n",
                "\n",
                "print(f\"\\nüî¥ Whole-text: {len(result_whole['detected_symptoms'])} symptoms, headache={headache_whole:.3f}\")\n",
                "for s, c in list(result_whole['confidence_scores'].items())[:5]:\n",
                "    print(f\"    {s}: {c:.3f}\")\n",
                "\n",
                "print(f\"\\n‚Üí Sentence-level {'BETTER' if headache_sent > headache_whole else 'worse'} at detecting 'headache'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.3 Comprehensive Test Suite"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comprehensive Test Results:\n",
                        "============================================================\n",
                        "\n",
                        "üìã Chest pain\n",
                        "   Input: \"sharp pain in my chest, feels like pressure\"\n",
                        "   Detected:\n",
                        "      ‚Ä¢ sharp chest pain: 0.493\n",
                        "      ‚Ä¢ chest pain: 0.486\n",
                        "\n",
                        "üìã Breathing\n",
                        "   Input: \"I can't catch my breath, feels like I'm suffocating\"\n",
                        "   Detected:\n",
                        "\n",
                        "üìã Cold symptoms\n",
                        "   Input: \"runny nose, sore throat, and sneezing a lot\"\n",
                        "   Detected:\n",
                        "      ‚Ä¢ sneezing: 0.471\n",
                        "\n",
                        "üìã Stomach\n",
                        "   Input: \"my stomach hurts after eating, lots of bloating\"\n",
                        "   Detected:\n",
                        "      ‚Ä¢ bloating: 0.460\n",
                        "\n",
                        "üìã Anxiety\n",
                        "   Input: \"feeling extremely anxious, can't calm down, heart racing\"\n",
                        "   Detected:\n",
                        "      ‚Ä¢ anxiety: 0.475\n",
                        "\n",
                        "üìã UTI\n",
                        "   Input: \"burning when I pee and need to go constantly\"\n",
                        "   Detected:\n",
                        "\n",
                        "üìã Fatigue\n",
                        "   Input: \"exhausted all the time, no energy to do anything\"\n",
                        "   Detected:\n",
                        "\n",
                        "üìã Fever\n",
                        "   Input: \"running a high temperature, chills and sweating\"\n",
                        "   Detected:\n",
                        "      ‚Ä¢ chills: 0.552\n"
                    ]
                }
            ],
            "source": [
                "test_cases = {\n",
                "    \"Chest pain\": \"sharp pain in my chest, feels like pressure\",\n",
                "    \"Breathing\": \"I can't catch my breath, feels like I'm suffocating\",\n",
                "    \"Cold symptoms\": \"runny nose, sore throat, and sneezing a lot\",\n",
                "    \"Stomach\": \"my stomach hurts after eating, lots of bloating\",\n",
                "    \"Anxiety\": \"feeling extremely anxious, can't calm down, heart racing\",\n",
                "    \"UTI\": \"burning when I pee and need to go constantly\",\n",
                "    \"Fatigue\": \"exhausted all the time, no energy to do anything\",\n",
                "    \"Fever\": \"running a high temperature, chills and sweating\",\n",
                "}\n",
                "\n",
                "print(\"Comprehensive Test Results:\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for category, text in test_cases.items():\n",
                "    result = encoder.encode_symptoms(text)\n",
                "    print(f\"\\nüìã {category}\")\n",
                "    print(f\"   Input: \\\"{text}\\\"\")\n",
                "    print(f\"   Detected:\")\n",
                "    for symptom, score in list(result['confidence_scores'].items())[:3]:\n",
                "        print(f\"      ‚Ä¢ {symptom}: {score:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.4 Edge Cases & Robustness"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Edge Case Testing:\n",
                        "============================================================\n",
                        "\n",
                        "Empty string: \"\"\n",
                        "  ‚Üí No symptoms detected\n",
                        "\n",
                        "Typo: headach: \"headach\"\n",
                        "  ‚Üí No symptoms detected\n",
                        "\n",
                        "Typo: stomache ake: \"stomache ake\"\n",
                        "  ‚Üí No symptoms detected\n",
                        "\n",
                        "Informal: tummy hurts: \"my tummy hurts so bad\"\n",
                        "  ‚Üí No symptoms detected\n",
                        "\n",
                        "Medical terms: \"experiencing dyspnea and tachycardia\"\n",
                        "  ‚Üí No symptoms detected\n",
                        "\n",
                        "Negation (known limitation): \"I don't have a headache\"\n",
                        "  ‚Üí No symptoms detected\n"
                    ]
                }
            ],
            "source": [
                "edge_cases = [\n",
                "    (\"\", \"Empty string\"),\n",
                "    (\"headach\", \"Typo: headach\"),\n",
                "    (\"stomache ake\", \"Typo: stomache ake\"),\n",
                "    (\"my tummy hurts so bad\", \"Informal: tummy hurts\"),\n",
                "    (\"experiencing dyspnea and tachycardia\", \"Medical terms\"),\n",
                "    (\"I don't have a headache\", \"Negation (known limitation)\"),\n",
                "]\n",
                "\n",
                "print(\"Edge Case Testing:\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for text, description in edge_cases:\n",
                "    result = encoder.encode_symptoms(text)\n",
                "    symptoms_found = list(result['confidence_scores'].items())[:3]\n",
                "    \n",
                "    print(f\"\\n{description}: \\\"{text}\\\"\")\n",
                "    if symptoms_found:\n",
                "        print(f\"  ‚Üí {', '.join([f'{s}({c:.2f})' for s, c in symptoms_found])}\")\n",
                "    else:\n",
                "        print(\"  ‚Üí No symptoms detected\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.5 Threshold Tuning\n",
                "\n",
                "Adjust threshold to balance precision vs recall:\n",
                "- Lower (0.4-0.5): More symptoms, may include false positives\n",
                "- Higher (0.6+): Fewer symptoms, higher precision"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing: \"I have chest pain, difficulty breathing, and headache\"\n",
                        "\n",
                        "Threshold 0.4: 13 symptoms\n",
                        "   difficulty breathing, chest pain, breathing problems, breathing fast, abnormal breathing sounds\n",
                        "Threshold 0.5: 3 symptoms\n",
                        "   difficulty breathing, chest pain, breathing problems\n",
                        "Threshold 0.6: 0 symptoms\n",
                        "   \n",
                        "Threshold 0.7: 0 symptoms\n",
                        "   \n"
                    ]
                }
            ],
            "source": [
                "test_text = \"I have chest pain, difficulty breathing, and headache\"\n",
                "print(f\"Testing: \\\"{test_text}\\\"\\n\")\n",
                "\n",
                "original_threshold = encoder.similarity_threshold\n",
                "\n",
                "for threshold in [0.4, 0.5, 0.6, 0.7]:\n",
                "    encoder.similarity_threshold = threshold\n",
                "    result = encoder.encode_symptoms(test_text)\n",
                "    print(f\"Threshold {threshold}: {len(result['detected_symptoms'])} symptoms\")\n",
                "    print(f\"   {', '.join(result['detected_symptoms'][:5])}\")\n",
                "\n",
                "encoder.similarity_threshold = original_threshold"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.6 Integration Test (Binary Vector for Classifier)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Binary vector for disease classifier:\n",
                        "  Shape: (480,)\n",
                        "  Non-zero features: 3\n",
                        "\n",
                        "Detected symptoms:\n",
                        "  ‚úì nausea (0.494)\n",
                        "  ‚úì nausea and vomitting (0.490)\n",
                        "  ‚úì vomiting (0.464)\n",
                        "\n",
                        "‚Üí This binary_vector can be fed directly to LightGBM classifiers!\n"
                    ]
                }
            ],
            "source": [
                "patient_description = \"\"\"\n",
                "I've been having severe headaches for the past week, especially in the morning.\n",
                "Also experiencing nausea, and the light bothers my eyes. Sometimes I see spots.\n",
                "\"\"\"\n",
                "\n",
                "result = encoder.encode_symptoms(patient_description)\n",
                "\n",
                "print(\"Binary vector for disease classifier:\")\n",
                "print(f\"  Shape: {result['binary_vector'].shape}\")\n",
                "print(f\"  Non-zero features: {int(np.sum(result['binary_vector'] > 0))}\")\n",
                "print(f\"\\nDetected symptoms:\")\n",
                "for symptom, score in sorted(result['confidence_scores'].items(), key=lambda x: x[1], reverse=True):\n",
                "    print(f\"  ‚úì {symptom} ({score:.3f})\")\n",
                "\n",
                "print(\"\\n‚Üí This binary_vector can be fed directly to LightGBM classifiers!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 3: Model Comparison\n",
                "\n",
                "Compare different sentence transformer models for the end-to-end semantic encoder ‚Üí disease classifier pipeline.\n",
                "\n",
                "**Goal**: Find the best model that maximizes:\n",
                "1. Symptom matching accuracy (colloquial text ‚Üí canonical symptoms)\n",
                "2. End-to-end pipeline accuracy (free text ‚Üí disease predictions)\n",
                "3. Reasonable inference time"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.1 Define Models to Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing 4 models:\n",
                        "  - all-MiniLM-L6-v2: Current default - Fast, 80MB\n",
                        "  - all-mpnet-base-v2: More accurate - 420MB\n",
                        "  - paraphrase-MiniLM-L6-v2: Good for paraphrases\n",
                        "  - multi-qa-mpnet-base-dot-v1: Optimized for Q&A\n"
                    ]
                }
            ],
            "source": [
                "# Sentence transformer models to compare\n",
                "MODELS_TO_TEST = [\n",
                "    (\"all-MiniLM-L12-v2\", \"Current default\")\n",
                "    (\"all-MiniLM-L6-v2\", \"Fast, 80MB\"),\n",
                "    (\"all-mpnet-base-v2\", \"More accurate - 420MB\"),\n",
                "    (\"paraphrase-MiniLM-L6-v2\", \"Good for paraphrases\"),\n",
                "    (\"multi-qa-mpnet-base-dot-v1\", \"Optimized for Q&A\"),\n",
                "]\n",
                "\n",
                "print(f\"Testing {len(MODELS_TO_TEST)} models:\")\n",
                "for model_name, desc in MODELS_TO_TEST:\n",
                "    print(f\"  - {model_name}: {desc}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.2 Load Test Data and Classifiers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded classifier with 656 diseases and 480 symptoms\n"
                    ]
                }
            ],
            "source": [
                "# Load the trained disease classifier\n",
                "checkpoint_dir = project_root / \"models\" / \"checkpoints\"\n",
                "from models.architectures.symptom_classifier import SymptomDiseaseClassifier\n",
                "\n",
                "disease_clf = SymptomDiseaseClassifier.load(str(checkpoint_dir / \"disease_classifier_demographics.pkl\"))\n",
                "disease_encoder_obj = joblib.load(checkpoint_dir / \"disease_encoder.pkl\")\n",
                "\n",
                "with open(checkpoint_dir / \"symptom_columns.json\") as f:\n",
                "    symptom_cols = json.load(f)\n",
                "\n",
                "print(f\"Loaded classifier with {len(disease_encoder_obj.classes_)} diseases and {len(symptom_cols)} symptoms\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing 10 symptoms with 40 phrases\n"
                    ]
                }
            ],
            "source": [
                "# Define test cases for symptom matching\n",
                "SYMPTOM_TEST_CASES = {\n",
                "    \"headache\": [\"my head is killing me\", \"terrible migraine\", \"pain in my head\", \"pounding headache\"],\n",
                "    \"fever\": [\"high temperature\", \"running a fever\", \"burning up\", \"I'm feverish\"],\n",
                "    \"nausea\": [\"feeling sick\", \"want to throw up\", \"queasy stomach\", \"feel like vomiting\"],\n",
                "    \"chest pain\": [\"hurts in my chest\", \"chest pressure\", \"sharp chest pain\", \"tightness in chest\"],\n",
                "    \"shortness of breath\": [\"can't breathe\", \"difficulty breathing\", \"out of breath\", \"hard to catch my breath\"],\n",
                "    \"fatigue\": [\"so tired\", \"exhausted\", \"no energy\", \"feeling drained\"],\n",
                "    \"cough\": [\"can't stop coughing\", \"bad cough\", \"coughing a lot\", \"persistent cough\"],\n",
                "    \"dizziness\": [\"feeling dizzy\", \"head spinning\", \"lightheaded\", \"vertigo\"],\n",
                "    \"abdominal pain\": [\"stomach hurts\", \"belly pain\", \"abdomen is sore\", \"gut pain\"],\n",
                "    \"vomiting\": [\"throwing up\", \"puking\", \"been vomiting\", \"can't keep food down\"],\n",
                "}\n",
                "\n",
                "print(f\"Testing {len(SYMPTOM_TEST_CASES)} symptoms with {sum(len(v) for v in SYMPTOM_TEST_CASES.values())} phrases\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing 8 patient descriptions\n"
                    ]
                }
            ],
            "source": [
                "# Create sample patient descriptions for end-to-end testing\n",
                "PATIENT_DESCRIPTIONS = [\n",
                "    (\"I have a terrible headache and feel nauseous. I also have a high temperature.\", [\"headache\", \"nausea\", \"fever\"]),\n",
                "    (\"My chest hurts and I can't breathe properly. I'm feeling very tired.\", [\"chest pain\", \"shortness of breath\", \"fatigue\"]),\n",
                "    (\"I've been throwing up all day and my stomach hurts really bad.\", [\"vomiting\", \"abdominal pain\", \"nausea\"]),\n",
                "    (\"Can't stop coughing, have a fever, and feel completely exhausted.\", [\"cough\", \"fever\", \"fatigue\"]),\n",
                "    (\"My head is spinning and I feel like I'm going to pass out.\", [\"dizziness\", \"lightheadedness\"]),\n",
                "    (\"Burning up with fever, body aches all over, and a nasty cough.\", [\"fever\", \"muscle pain\", \"cough\"]),\n",
                "    (\"Sharp pain in my chest when I breathe, feeling short of breath.\", [\"chest pain\", \"shortness of breath\"]),\n",
                "    (\"Throwing up, diarrhea, and terrible stomach cramps.\", [\"vomiting\", \"diarrhea\", \"abdominal pain\"]),\n",
                "]\n",
                "\n",
                "print(f\"Testing {len(PATIENT_DESCRIPTIONS)} patient descriptions\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.3 Model Comparison Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sentence_transformers import SentenceTransformer\n",
                "\n",
                "def create_encoder_with_model(model_name, symptom_vocab_path=None, similarity_threshold=0.35, top_k=25):\n",
                "    \"\"\"Create a semantic encoder with a specific model.\"\"\"\n",
                "    from models.architectures.semantic_symptom_encoder import SemanticSymptomEncoder\n",
                "    \n",
                "    # Create a unique cache path for this model\n",
                "    cache_dir = project_root / \"data\" / \"embeddings\"\n",
                "    cache_path = cache_dir / f\"semantic_symptom_embeddings_{model_name.replace('/', '_')}.npy\"\n",
                "    \n",
                "    encoder = SemanticSymptomEncoder(\n",
                "        model_name=model_name,\n",
                "        embeddings_cache_path=str(cache_path),\n",
                "        similarity_threshold=similarity_threshold,\n",
                "        top_k=top_k\n",
                "    )\n",
                "    return encoder\n",
                "\n",
                "def test_symptom_matching(encoder, test_cases):\n",
                "    \"\"\"Test how well the encoder matches colloquial phrases to canonical symptoms.\"\"\"\n",
                "    results = {}\n",
                "    total_correct = 0\n",
                "    total_tests = 0\n",
                "    \n",
                "    for target_symptom, phrases in test_cases.items():\n",
                "        matches = 0\n",
                "        for phrase in phrases:\n",
                "            result = encoder.encode_symptoms(phrase)\n",
                "            detected = result['detected_symptoms'][:5]  # Top 5 matches\n",
                "            # Check if target symptom (or close match) is in detected\n",
                "            if any(target_symptom in s or s in target_symptom for s in detected):\n",
                "                matches += 1\n",
                "        \n",
                "        results[target_symptom] = matches / len(phrases)\n",
                "        total_correct += matches\n",
                "        total_tests += len(phrases)\n",
                "    \n",
                "    overall_accuracy = total_correct / total_tests\n",
                "    return overall_accuracy, results\n",
                "\n",
                "def test_end_to_end_pipeline(encoder, disease_clf, patient_descriptions, symptom_cols):\n",
                "    \"\"\"Test the full pipeline: text ‚Üí encoder ‚Üí classifier ‚Üí prediction.\"\"\"\n",
                "    times = []\n",
                "    symptom_recall_scores = []\n",
                "    \n",
                "    for description, expected_symptoms in patient_descriptions:\n",
                "        start_time = time.time()\n",
                "        \n",
                "        # Step 1: Encode symptoms\n",
                "        result = encoder.encode_symptoms(description)\n",
                "        detected_symptoms = result['detected_symptoms']\n",
                "        \n",
                "        # Step 2: Create feature vector\n",
                "        feature_vector = np.zeros(len(symptom_cols) + 2)  # +2 for age, sex\n",
                "        for symptom in detected_symptoms:\n",
                "            if symptom in symptom_cols:\n",
                "                idx = symptom_cols.index(symptom)\n",
                "                feature_vector[idx] = 1.0\n",
                "        \n",
                "        # Add demographics (use average values)\n",
                "        feature_vector[-2] = 0.35  # age_normalized\n",
                "        feature_vector[-1] = 0.5   # sex_encoded\n",
                "        \n",
                "        end_time = time.time()\n",
                "        times.append(end_time - start_time)\n",
                "        \n",
                "        # Calculate symptom recall\n",
                "        matched = sum(1 for s in expected_symptoms if any(s in d or d in s for d in detected_symptoms))\n",
                "        recall = matched / len(expected_symptoms) if expected_symptoms else 0\n",
                "        symptom_recall_scores.append(recall)\n",
                "    \n",
                "    avg_time = np.mean(times) * 1000  # Convert to ms\n",
                "    avg_symptom_recall = np.mean(symptom_recall_scores)\n",
                "    \n",
                "    return {\n",
                "        'avg_time_ms': avg_time,\n",
                "        'symptom_recall': avg_symptom_recall\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.4 Run Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing models:   0%|          | 0/4 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "Testing: all-MiniLM-L6-v2\n",
                        "Description: Current default - Fast, 80MB\n",
                        "============================================================\n",
                        "Loading sentence transformer model: all-MiniLM-L6-v2\n",
                        "Loading cached symptom embeddings from c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\embeddings\\semantic_symptom_embeddings_all-MiniLM-L6-v2.npy\n",
                        "Computing symptom embeddings (this is a one-time operation)...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:11<00:00,  1.30it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved symptom embeddings to c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\embeddings\\semantic_symptom_embeddings_all-MiniLM-L6-v2.npy\n",
                        "Semantic Symptom Encoder initialized with 480 symptoms\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing models:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:16<00:48, 16.12s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Symptom Matching Accuracy: 60.0%\n",
                        "Pipeline Symptom Recall: 79.2%\n",
                        "Average Inference Time: 19.2ms\n",
                        "\n",
                        "============================================================\n",
                        "Testing: all-mpnet-base-v2\n",
                        "Description: More accurate - 420MB\n",
                        "============================================================\n",
                        "Loading sentence transformer model: all-mpnet-base-v2\n",
                        "Loading cached symptom embeddings from c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\embeddings\\semantic_symptom_embeddings_all-mpnet-base-v2.npy\n",
                        "Computing symptom embeddings (this is a one-time operation)...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [01:08<00:00,  4.54s/it]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved symptom embeddings to c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\embeddings\\semantic_symptom_embeddings_all-mpnet-base-v2.npy\n",
                        "Semantic Symptom Encoder initialized with 480 symptoms\n",
                        "\n",
                        "Symptom Matching Accuracy: 80.0%\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing models:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [01:31<01:41, 50.81s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Pipeline Symptom Recall: 62.5%\n",
                        "Average Inference Time: 76.2ms\n",
                        "\n",
                        "============================================================\n",
                        "Testing: paraphrase-MiniLM-L6-v2\n",
                        "Description: Good for paraphrases\n",
                        "============================================================\n",
                        "Loading sentence transformer model: paraphrase-MiniLM-L6-v2\n",
                        "Loading cached symptom embeddings from c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\embeddings\\semantic_symptom_embeddings_paraphrase-MiniLM-L6-v2.npy\n",
                        "Computing symptom embeddings (this is a one-time operation)...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.37it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved symptom embeddings to c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\embeddings\\semantic_symptom_embeddings_paraphrase-MiniLM-L6-v2.npy\n",
                        "Semantic Symptom Encoder initialized with 480 symptoms\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing models:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [01:46<00:34, 34.74s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Symptom Matching Accuracy: 52.5%\n",
                        "Pipeline Symptom Recall: 68.8%\n",
                        "Average Inference Time: 18.6ms\n",
                        "\n",
                        "============================================================\n",
                        "Testing: multi-qa-mpnet-base-dot-v1\n",
                        "Description: Optimized for Q&A\n",
                        "============================================================\n",
                        "Loading sentence transformer model: multi-qa-mpnet-base-dot-v1\n",
                        "Loading cached symptom embeddings from c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\embeddings\\semantic_symptom_embeddings_multi-qa-mpnet-base-dot-v1.npy\n",
                        "Computing symptom embeddings (this is a one-time operation)...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 11/15 [01:03<00:22,  5.74s/it]\n",
                        "Testing models:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [02:53<00:57, 57.99s/it]\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[44], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Create encoder with this model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     test_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_encoder_with_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Test 1: Symptom matching accuracy\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     symptom_accuracy, symptom_details \u001b[38;5;241m=\u001b[39m test_symptom_matching(test_encoder, SYMPTOM_TEST_CASES)\n",
                        "Cell \u001b[1;32mIn[43], line 11\u001b[0m, in \u001b[0;36mcreate_encoder_with_model\u001b[1;34m(model_name, symptom_vocab_path, similarity_threshold, top_k)\u001b[0m\n\u001b[0;32m      8\u001b[0m cache_dir \u001b[38;5;241m=\u001b[39m project_root \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m cache_path \u001b[38;5;241m=\u001b[39m cache_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msemantic_symptom_embeddings_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mSemanticSymptomEncoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings_cache_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msimilarity_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilarity_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoder\n",
                        "File \u001b[1;32mc:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\models\\architectures\\semantic_symptom_encoder.py:95\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, model_name, symptom_vocab_path, embeddings_cache_path, similarity_threshold, top_k, device)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_enrich_symptom\u001b[39m(\u001b[38;5;28mself\u001b[39m, symptom: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[0;32m     92\u001b[0m         symptom,\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymptom\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI feel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymptom\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m---> 95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuffering from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymptom\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymptoms of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymptom\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymptom\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     ])\n",
                        "File \u001b[1;32mc:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\models\\architectures\\semantic_symptom_encoder.py:124\u001b[0m, in \u001b[0;36m_load_or_compute_embeddings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m     np.save(self.embeddings_cache_path, emb)\n\u001b[0;32m    122\u001b[0m     return emb\n\u001b[1;32m--> 124\u001b[0m # ------------------------------------------------------------------\n\u001b[0;32m    125\u001b[0m # Core API\n\u001b[0;32m    126\u001b[0m # ------------------------------------------------------------------\n\u001b[0;32m    128\u001b[0m def encode_symptoms(self, text: str) -> Dict[str, Any]:\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m    130\u001b[0m     Convert free-form symptom text into a 377-dim continuous\n\u001b[0;32m    131\u001b[0m     symptom evidence vector (0‚Äì1).\n\u001b[0;32m    132\u001b[0m     \"\"\"\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1094\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m   1091\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1094\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1096\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[1;34m(self, input, **kwargs)\u001b[0m\n\u001b[0;32m   1169\u001b[0m             module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[0;32m   1170\u001b[0m         module_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1171\u001b[0m             key: value\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1173\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mforward_kwargs)\n\u001b[0;32m   1174\u001b[0m         }\n\u001b[1;32m-> 1175\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs)\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:262\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    260\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward_params}\n\u001b[1;32m--> 262\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrans_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    263\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    264\u001b[0m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token_embeddings\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:486\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    485\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[1;32m--> 486\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    495\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:338\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    336\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m--> 338\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    339\u001b[0m     hidden_states,\n\u001b[0;32m    340\u001b[0m     attention_mask,\n\u001b[0;32m    341\u001b[0m     head_mask[i],\n\u001b[0;32m    342\u001b[0m     position_bias,\n\u001b[0;32m    343\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    345\u001b[0m )\n\u001b[0;32m    346\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:297\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    290\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    296\u001b[0m ):\n\u001b[1;32m--> 297\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    305\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:238\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    231\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    237\u001b[0m ):\n\u001b[1;32m--> 238\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(self_outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m hidden_states)\n\u001b[0;32m    246\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:198\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m new_c_shape \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size,)\n\u001b[0;32m    196\u001b[0m c \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mnew_c_shape)\n\u001b[1;32m--> 198\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (o, attention_probs) \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m (o,)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\henry\\.conda\\envs\\multimodal\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# Run comparison across all models\n",
                "comparison_results = []\n",
                "\n",
                "for model_name, model_desc in tqdm(MODELS_TO_TEST, desc=\"Testing models\"):\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Testing: {model_name}\")\n",
                "    print(f\"Description: {model_desc}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    try:\n",
                "        # Create encoder with this model\n",
                "        test_encoder = create_encoder_with_model(model_name)\n",
                "        \n",
                "        # Test 1: Symptom matching accuracy\n",
                "        symptom_accuracy, symptom_details = test_symptom_matching(test_encoder, SYMPTOM_TEST_CASES)\n",
                "        print(f\"\\nSymptom Matching Accuracy: {symptom_accuracy*100:.1f}%\")\n",
                "        \n",
                "        # Test 2: End-to-end pipeline\n",
                "        pipeline_results = test_end_to_end_pipeline(\n",
                "            test_encoder, disease_clf, PATIENT_DESCRIPTIONS, symptom_cols\n",
                "        )\n",
                "        print(f\"Pipeline Symptom Recall: {pipeline_results['symptom_recall']*100:.1f}%\")\n",
                "        print(f\"Average Inference Time: {pipeline_results['avg_time_ms']:.1f}ms\")\n",
                "        \n",
                "        comparison_results.append({\n",
                "            'Model': model_name,\n",
                "            'Description': model_desc,\n",
                "            'Symptom Match %': symptom_accuracy * 100,\n",
                "            'Pipeline Recall %': pipeline_results['symptom_recall'] * 100,\n",
                "            'Time (ms)': pipeline_results['avg_time_ms'],\n",
                "            'Per-Symptom': symptom_details\n",
                "        })\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error testing {model_name}: {e}\")\n",
                "        comparison_results.append({\n",
                "            'Model': model_name,\n",
                "            'Description': model_desc,\n",
                "            'Symptom Match %': 0,\n",
                "            'Pipeline Recall %': 0,\n",
                "            'Time (ms)': 0,\n",
                "            'Error': str(e)\n",
                "        })"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.5 Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "MODEL COMPARISON RESULTS\n",
                        "================================================================================\n",
                        "                     Model                  Description  Symptom Match %  Pipeline Recall %  Time (ms)\n",
                        "          all-MiniLM-L6-v2 Current default - Fast, 80MB             60.0          79.166667  19.407392\n",
                        "         all-mpnet-base-v2        More accurate - 420MB             80.0          62.500000  80.675781\n",
                        "   paraphrase-MiniLM-L6-v2         Good for paraphrases             52.5          68.750000  25.872588\n",
                        "multi-qa-mpnet-base-dot-v1            Optimized for Q&A             90.0          95.833333  99.580258\n"
                    ]
                }
            ],
            "source": [
                "# Create summary dataframe\n",
                "df_results = pd.DataFrame(comparison_results)\n",
                "df_summary = df_results[['Model', 'Description', 'Symptom Match %', 'Pipeline Recall %', 'Time (ms)']].copy()\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"MODEL COMPARISON RESULTS\")\n",
                "print(\"=\"*80)\n",
                "print(df_summary.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1500x500 with 3 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Visualization\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "models = df_summary['Model'].str.replace('all-', '').str.replace('-v2', '')\n",
                "\n",
                "# Symptom Matching\n",
                "axes[0].barh(models, df_summary['Symptom Match %'], color='steelblue')\n",
                "axes[0].set_xlabel('Accuracy (%)')\n",
                "axes[0].set_title('Symptom Matching Accuracy')\n",
                "axes[0].set_xlim([0, 100])\n",
                "for i, v in enumerate(df_summary['Symptom Match %']):\n",
                "    axes[0].text(v + 1, i, f'{v:.1f}%', va='center')\n",
                "\n",
                "# Pipeline Recall\n",
                "axes[1].barh(models, df_summary['Pipeline Recall %'], color='coral')\n",
                "axes[1].set_xlabel('Recall (%)')\n",
                "axes[1].set_title('Pipeline Symptom Recall')\n",
                "axes[1].set_xlim([0, 100])\n",
                "for i, v in enumerate(df_summary['Pipeline Recall %']):\n",
                "    axes[1].text(v + 1, i, f'{v:.1f}%', va='center')\n",
                "\n",
                "# Inference Time\n",
                "axes[2].barh(models, df_summary['Time (ms)'], color='green')\n",
                "axes[2].set_xlabel('Time (ms)')\n",
                "axes[2].set_title('Avg Inference Time per Sample')\n",
                "for i, v in enumerate(df_summary['Time (ms)']):\n",
                "    axes[2].text(v + 0.5, i, f'{v:.1f}ms', va='center')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(project_root / 'notebooks' / 'figures' / 'semantic_model_comparison_results.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.6 Per-Symptom Breakdown"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "all-MiniLM-L6-v2:\n",
                        "  headache                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n",
                        "  fever                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n",
                        "  nausea                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "  chest pain                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "  shortness of breath       ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
                        "  fatigue                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "  cough                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  dizziness                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "  abdominal pain            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  vomiting                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "\n",
                        "all-mpnet-base-v2:\n",
                        "  headache                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n",
                        "  fever                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n",
                        "  nausea                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  chest pain                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  shortness of breath       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n",
                        "  fatigue                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n",
                        "  cough                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  dizziness                 ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  25.0%\n",
                        "  abdominal pain            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  vomiting                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n",
                        "\n",
                        "paraphrase-MiniLM-L6-v2:\n",
                        "  headache                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "  fever                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "  nausea                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "  chest pain                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n",
                        "  shortness of breath       ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
                        "  fatigue                   ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  25.0%\n",
                        "  cough                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  dizziness                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "  abdominal pain            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  vomiting                  ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  25.0%\n",
                        "\n",
                        "multi-qa-mpnet-base-dot-v1:\n",
                        "  headache                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  fever                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n",
                        "  nausea                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  chest pain                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  shortness of breath       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  50.0%\n",
                        "  fatigue                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  cough                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  dizziness                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  abdominal pain            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
                        "  vomiting                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  75.0%\n"
                    ]
                }
            ],
            "source": [
                "# Show per-symptom performance for each model\n",
                "for result in comparison_results:\n",
                "    if 'Per-Symptom' in result:\n",
                "        print(f\"\\n{result['Model']}:\")\n",
                "        for symptom, acc in result['Per-Symptom'].items():\n",
                "            bar = '‚ñà' * int(acc * 10) + '‚ñë' * (10 - int(acc * 10))\n",
                "            print(f\"  {symptom:25s} {bar} {acc*100:5.1f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.7 Recommendations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RECOMMENDATIONS\n",
                        "============================================================\n",
                        "\n",
                        "üìä Best Symptom Matching: multi-qa-mpnet-base-dot-v1 (90.0%)\n",
                        "üéØ Best Pipeline Recall:  multi-qa-mpnet-base-dot-v1 (95.8%)\n",
                        "‚ö° Fastest Inference:     all-MiniLM-L6-v2 (19.4ms)\n",
                        "\n",
                        "üèÜ RECOMMENDED MODEL: multi-qa-mpnet-base-dot-v1\n",
                        "   Overall Score: 74.4\n"
                    ]
                }
            ],
            "source": [
                "# Find best model\n",
                "best_accuracy = df_summary.loc[df_summary['Symptom Match %'].idxmax()]\n",
                "best_speed = df_summary.loc[df_summary['Time (ms)'].idxmin()]\n",
                "best_recall = df_summary.loc[df_summary['Pipeline Recall %'].idxmax()]\n",
                "\n",
                "print(\"RECOMMENDATIONS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nüìä Best Symptom Matching: {best_accuracy['Model']} ({best_accuracy['Symptom Match %']:.1f}%)\")\n",
                "print(f\"üéØ Best Pipeline Recall:  {best_recall['Model']} ({best_recall['Pipeline Recall %']:.1f}%)\")\n",
                "print(f\"‚ö° Fastest Inference:     {best_speed['Model']} ({best_speed['Time (ms)']:.1f}ms)\")\n",
                "\n",
                "# Calculate overall score (weighted)\n",
                "df_summary['Overall Score'] = (\n",
                "    df_summary['Symptom Match %'] * 0.4 + \n",
                "    df_summary['Pipeline Recall %'] * 0.4 + \n",
                "    (100 - df_summary['Time (ms)'].clip(0, 100)) * 0.2\n",
                ")\n",
                "best_overall = df_summary.loc[df_summary['Overall Score'].idxmax()]\n",
                "print(f\"\\nüèÜ RECOMMENDED MODEL: {best_overall['Model']}\")\n",
                "print(f\"   Overall Score: {best_overall['Overall Score']:.1f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Results saved to: c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\models\\checkpoints\\semantic_model_comparison_results.json\n"
                    ]
                }
            ],
            "source": [
                "# Save results\n",
                "results_path = project_root / 'models' / 'checkpoints' / 'semantic_model_comparison_results.json'\n",
                "\n",
                "# Convert to serializable format\n",
                "export_results = []\n",
                "for r in comparison_results:\n",
                "    export_r = {k: v for k, v in r.items() if k != 'Per-Symptom'}\n",
                "    if 'Per-Symptom' in r:\n",
                "        export_r['Per-Symptom'] = {k: float(v) for k, v in r['Per-Symptom'].items()}\n",
                "    export_results.append(export_r)\n",
                "\n",
                "with open(results_path, 'w') as f:\n",
                "    json.dump(export_results, f, indent=2)\n",
                "\n",
                "print(f\"\\nResults saved to: {results_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Summary\n",
                "\n",
                "**Training:**\n",
                "- Vocabulary: `data/symptom_vocabulary.json` (480 symptoms)\n",
                "- Embeddings: `data/embeddings/semantic_symptom_embeddings.npy`\n",
                "- Model: multi-qa-mpnet-base-dot-v1 (768-dim embeddings)\n",
                "\n",
                "**Recommended Settings:**\n",
                "- `similarity_threshold`: 0.45-0.50\n",
                "- `top_k`: 15-20\n",
                "- `use_sentence_level`: True (default)\n",
                "\n",
                "**Known Limitations:**\n",
                "- Negation not handled (\"I don't have fever\" may detect fever)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Semantic Symptom Encoder ready!\n",
                        "\n",
                        "Configuration:\n",
                        "  Model: multi-qa-mpnet-base-dot-v1\n",
                        "  Symptoms: 480\n",
                        "  Threshold: 0.45\n",
                        "  Top-K: 20\n"
                    ]
                }
            ],
            "source": [
                "print(\"‚úÖ Semantic Symptom Encoder ready!\")\n",
                "print(f\"\\nConfiguration:\")\n",
                "print(f\"  Model: {encoder.model_name}\")\n",
                "print(f\"  Symptoms: {len(encoder.symptoms)}\")\n",
                "print(f\"  Threshold: {encoder.similarity_threshold}\")\n",
                "print(f\"  Top-K: {encoder.top_k}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "multimodal",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
