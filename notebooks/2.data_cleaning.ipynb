{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2191f5f",
   "metadata": {},
   "source": [
    "# Data Cleaning: Symptom-Disease Dataset\n",
    "\n",
    "This notebook cleans and prepares the raw symptom-disease data for training.\n",
    "\n",
    "## Table of Contents\n",
    "1. **Setup & Imports** - Load libraries and constants\n",
    "2. **Data Loading** - Load raw dataset\n",
    "3. **Disease Filtering** - Remove non-predictable diseases\n",
    "4. **Category Assignment** - Map diseases to categories\n",
    "5. **Data Quality Checks** - Verify integrity\n",
    "6. **Symptom Normalization** - Standardize symptom columns\n",
    "7. **Save Cleaned Data** - Export processed dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Project setup\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project utilities and constants\n",
    "from utils.symptom_normalizer import normalize_symptom, validate_vocabulary\n",
    "from utils.consts import (\n",
    "    TYPO_MAP, SYNONYM_MAP, PLURAL_MAP,\n",
    "    NON_SYMPTOM_COLS, DISEASES_TO_EXCLUDE\n",
    ")\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Loaded {len(DISEASES_TO_EXCLUDE)} diseases to exclude\")\n",
    "print(f\"Loaded {len(TYPO_MAP)} typo rules, {len(SYNONYM_MAP)} synonym rules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6158d315",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "symptomsToDisease = pd.read_csv(project_root / 'data/raw/symptoms/Disease and symptoms dataset.csv')\n",
    "\n",
    "original_rows = len(symptomsToDisease)\n",
    "original_cols = len(symptomsToDisease.columns)\n",
    "symptom_cols = [c for c in symptomsToDisease.columns if c != 'diseases']\n",
    "\n",
    "print(f\"Loaded dataset: {original_rows:,} rows x {original_cols} columns\")\n",
    "print(f\"Symptom columns: {len(symptom_cols)}\")\n",
    "print(f\"Unique diseases: {symptomsToDisease['diseases'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36c39bf",
   "metadata": {},
   "source": [
    "## 2. Disease Filtering\n",
    "\n",
    "Remove diseases that are diagnosed via physical trauma, imaging, or lab tests rather than symptom patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-predictable diseases using centralized constant\n",
    "print(f\"Diseases to exclude: {len(DISEASES_TO_EXCLUDE)}\")\n",
    "\n",
    "# Check which diseases from exclusion list are actually in our data\n",
    "diseases_in_data = set(symptomsToDisease['diseases'].str.lower().str.strip().unique())\n",
    "exclusions_found = set(d.lower() for d in DISEASES_TO_EXCLUDE) & diseases_in_data\n",
    "print(f\"Exclusions matching our data: {len(exclusions_found)}\")\n",
    "\n",
    "# Apply filter\n",
    "symptomsToDisease = symptomsToDisease[\n",
    "    ~symptomsToDisease['diseases'].str.lower().str.strip().isin(\n",
    "        [d.lower().strip() for d in DISEASES_TO_EXCLUDE]\n",
    "    )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"  Rows: {len(symptomsToDisease):,} (removed {original_rows - len(symptomsToDisease):,})\")\n",
    "print(f\"  Diseases: {symptomsToDisease['diseases'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78addf7a",
   "metadata": {},
   "source": [
    "## 3. Category Assignment\n",
    "\n",
    "Map each disease to a medical category using the disease_mapping.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load disease-to-category mapping\n",
    "with open(project_root / 'data/disease_mapping.json') as f:\n",
    "    category_map = json.load(f)\n",
    "\n",
    "# Create flat lookup\n",
    "disease_to_category = {\n",
    "    disease: category\n",
    "    for category, diseases in category_map.items()\n",
    "    for disease in diseases\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "symptomsToDisease['disease_category'] = symptomsToDisease['diseases'].map(disease_to_category)\n",
    "symptomsToDisease['disease_category'].fillna('Unknown Type', inplace=True)\n",
    "\n",
    "# Show category distribution\n",
    "print(\"Category Distribution:\")\n",
    "for cat, count in symptomsToDisease['disease_category'].value_counts().items():\n",
    "    print(f\"  {cat:35s}: {count:5d} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef81cf9",
   "metadata": {},
   "source": [
    "## 4. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88084018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = symptomsToDisease.isnull().sum().sum()\n",
    "print(f\"Missing values: {missing}\")\n",
    "\n",
    "# Check symptoms per patient\n",
    "symptoms_per_patient = symptomsToDisease[symptom_cols].sum(axis=1)\n",
    "print(f\"\\nSymptoms per patient:\")\n",
    "print(f\"  Mean: {symptoms_per_patient.mean():.2f}\")\n",
    "print(f\"  Min:  {symptoms_per_patient.min():.0f}\")\n",
    "print(f\"  Max:  {symptoms_per_patient.max():.0f}\")\n",
    "\n",
    "# Check disease distribution\n",
    "disease_counts = symptomsToDisease['diseases'].value_counts()\n",
    "print(f\"\\nDisease distribution:\")\n",
    "print(f\"  Total diseases: {len(disease_counts)}\")\n",
    "print(f\"  Min samples:    {disease_counts.min()}\")\n",
    "print(f\"  Max samples:    {disease_counts.max()}\")\n",
    "print(f\"  Imbalance:      {disease_counts.max() / disease_counts.min():.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f816a",
   "metadata": {},
   "source": [
    "## 5. Symptom Normalization\n",
    "\n",
    "Standardize symptom column names using the normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b28a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_processing_targets(columns: list) -> dict:\n",
    "    \"\"\"Find columns that normalize to the same symptom or need renaming.\"\"\"\n",
    "    normalized_map = {}\n",
    "    for col in columns:\n",
    "        if col.lower() in NON_SYMPTOM_COLS:\n",
    "            continue\n",
    "        norm = normalize_symptom(col)\n",
    "        if norm not in normalized_map:\n",
    "            normalized_map[norm] = []\n",
    "        normalized_map[norm].append(col)\n",
    "    \n",
    "    targets = {}\n",
    "    for norm, cols in normalized_map.items():\n",
    "        if len(cols) > 1 or (len(cols) == 1 and cols[0] != norm):\n",
    "            targets[norm] = cols\n",
    "    return targets\n",
    "\n",
    "def apply_normalization(df: pd.DataFrame, name: str = 'DataFrame'):\n",
    "    \"\"\"Apply symptom normalization to a dataframe.\"\"\"\n",
    "    print(f\"\\nProcessing: {name}...\")\n",
    "    targets = find_processing_targets(df.columns.tolist())\n",
    "    \n",
    "    if not targets:\n",
    "        print(\"  -> No changes needed.\")\n",
    "        return df, False\n",
    "    \n",
    "    for canonical, cols in targets.items():\n",
    "        if len(cols) > 1:\n",
    "            # Merge columns\n",
    "            df[canonical] = df[cols].max(axis=1)\n",
    "            df.drop(columns=cols, inplace=True)\n",
    "            print(f\"  Merged {cols} -> '{canonical}'\")\n",
    "        else:\n",
    "            # Rename column\n",
    "            df.rename(columns={cols[0]: canonical}, inplace=True)\n",
    "            print(f\"  Renamed '{cols[0]}' -> '{canonical}'\")\n",
    "    \n",
    "    return df, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization\n",
    "symptomsToDisease, changed = apply_normalization(symptomsToDisease, 'symptomsToDisease')\n",
    "print(f\"\\nFinal shape: {symptomsToDisease.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1229ee10",
   "metadata": {},
   "source": [
    "## 6. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize memory before saving\n",
    "for col in symptomsToDisease.select_dtypes(include=['float']).columns:\n",
    "    symptomsToDisease[col] = pd.to_numeric(symptomsToDisease[col], downcast='float')\n",
    "for col in symptomsToDisease.select_dtypes(include=['int']).columns:\n",
    "    symptomsToDisease[col] = pd.to_numeric(symptomsToDisease[col], downcast='integer')\n",
    "\n",
    "# Save\n",
    "output_path = project_root / 'data/processed/symptoms/symptoms_to_disease_cleaned.csv'\n",
    "symptomsToDisease.to_csv(output_path, index=False)\n",
    "print(f\"Saved to: {output_path}\")\n",
    "print(f\"File size: {output_path.stat().st_size / 1024**2:.2f} MB\")\n",
    "\n",
    "# Cleanup\n",
    "del symptomsToDisease\n",
    "gc.collect()\n",
    "print(\"Memory cleared.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
