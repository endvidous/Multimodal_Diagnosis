{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Augmentation Pipeline v2.0\n",
                "\n",
                "**For Research Paper**: Complete pipeline for augmenting the symptom-disease dataset.\n",
                "\n",
                "## Pipeline Overview\n",
                "\n",
                "| Stage | Description | Output |\n",
                "|-------|-------------|--------|\n",
                "| **0** | Expand symptom vocabulary with Mayo Clinic symptoms | `symptom_columns.json` (updated) |\n",
                "| **1** | Generate synthetic samples for rare diseases (<20 samples) | `symptoms_augmented_no_demographics.csv` |\n",
                "| **2** | Add demographic variables (age, sex) | `symptoms_augmented_with_demographics.csv` |\n",
                "\n",
                "## Requirements\n",
                "- `data/rare_diseases_symptoms_template.json` - Filled with Mayo Clinic symptoms\n",
                "- `data/final_disease_demographics.json` - Demographics from ChatGPT + synthetic rules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Project root: c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\n",
                        "\n",
                        "Input files:\n",
                        "  Data: True - c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\processed\\symptoms\\symptoms_to_disease_cleaned.csv\n",
                        "  Vocab: True - c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\models\\checkpoints\\symptom_columns.json\n",
                        "  Template: True - c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\rare_diseases_symptoms_template.json\n",
                        "  Demographics: True - c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\final_disease_demographics.json\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "import json\n",
                "import re\n",
                "import random\n",
                "from collections import Counter\n",
                "\n",
                "# Paths\n",
                "project_root = Path.cwd().parent\n",
                "\n",
                "# Input files\n",
                "data_path = project_root / \"data\" / \"processed\" / \"symptoms\" / \"symptoms_to_disease_cleaned.csv\"\n",
                "symptom_cols_path = project_root / \"models\" / \"checkpoints\" / \"symptom_columns.json\"\n",
                "template_path = project_root / \"data\" / \"rare_diseases_symptoms_template.json\"\n",
                "category_map_path = project_root / \"data\" / \"disease_mapping.json\"\n",
                "demographics_path = project_root / \"data\" / \"final_disease_demographics.json\"\n",
                "\n",
                "# Output files - vocabulary saved to SAME file (overwrites original)\n",
                "expanded_vocab_path = symptom_cols_path  # Overwrites original\n",
                "output_no_demo_path = project_root / \"data\" / \"processed\" / \"symptoms\" / \"symptoms_augmented_no_demographics.csv\"\n",
                "output_with_demo_path = project_root / \"data\" / \"processed\" / \"symptoms\" / \"symptoms_augmented_with_demographics.csv\"\n",
                "\n",
                "print(f\"Project root: {project_root}\")\n",
                "print(f\"\\nInput files:\")\n",
                "print(f\"  Data: {data_path.exists()} - {data_path}\")\n",
                "print(f\"  Vocab: {symptom_cols_path.exists()} - {symptom_cols_path}\")\n",
                "print(f\"  Template: {template_path.exists()} - {template_path}\")\n",
                "print(f\"  Demographics: {demographics_path.exists()} - {demographics_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Stage 0: Expand Symptom Vocabulary\n",
                "\n",
                "The current vocabulary has 377 symptoms. Many Mayo Clinic symptoms don't have exact matches.\n",
                "\n",
                "**Strategy**: Add clinically important new symptoms to the vocabulary (appearing in 5+ diseases)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original vocabulary: 377 symptoms\n",
                        "Diseases in template: 135\n"
                    ]
                }
            ],
            "source": [
                "# Load current vocabulary\n",
                "with open(symptom_cols_path) as f:\n",
                "    ORIGINAL_VOCAB = json.load(f)\n",
                "ORIGINAL_SET = set(s.lower() for s in ORIGINAL_VOCAB)\n",
                "\n",
                "print(f\"Original vocabulary: {len(ORIGINAL_VOCAB)} symptoms\")\n",
                "\n",
                "# Load template with Mayo Clinic symptoms\n",
                "with open(template_path) as f:\n",
                "    template = json.load(f)\n",
                "\n",
                "print(f\"Diseases in template: {len(template)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total unique mayo symptoms: 766\n",
                        "New symptoms (not in vocabulary): 706\n"
                    ]
                }
            ],
            "source": [
                "# Extract all unique symptoms from template\n",
                "all_mayo_symptoms = set()\n",
                "symptom_counts = Counter()\n",
                "\n",
                "for disease, info in template.items():\n",
                "    mayo = info.get(\"mayo_clinic_symptoms\", [])\n",
                "    for sym in mayo:\n",
                "        sym_clean = sym.strip().lower()\n",
                "        if sym_clean and not sym_clean.startswith('\"notes\"'):\n",
                "            all_mayo_symptoms.add(sym_clean)\n",
                "            symptom_counts[sym_clean] += 1\n",
                "\n",
                "print(f\"Total unique mayo symptoms: {len(all_mayo_symptoms)}\")\n",
                "\n",
                "# Find symptoms NOT in current vocabulary\n",
                "new_symptoms = [s for s in all_mayo_symptoms if s not in ORIGINAL_SET]\n",
                "print(f\"New symptoms (not in vocabulary): {len(new_symptoms)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Most common new symptoms (top 50):\n",
                        "------------------------------------------------------------\n",
                        "  [15x] confusion\n",
                        "  [11x] chest pain\n",
                        "  [ 9x] abdominal pain\n",
                        "  [ 8x] weight loss\n",
                        "  [ 8x] irritability\n",
                        "  [ 7x] high blood pressure\n",
                        "  [ 7x] blurred vision\n",
                        "  [ 7x] loss of apetite\n",
                        "  [ 6x] low blood pressure\n",
                        "  [ 6x] muscle aches\n",
                        "  [ 5x] bone pain\n",
                        "  [ 5x] eye pain\n",
                        "  [ 5x] rash\n",
                        "  [ 5x] headaches\n",
                        "  [ 4x] slurred speech\n",
                        "  [ 4x] anxiety\n",
                        "  [ 4x] tiredness\n",
                        "  [ 4x] lightheadedness\n",
                        "  [ 4x] stomach pain\n",
                        "  [ 4x] difficulty swallowing\n",
                        "  [ 4x] drowsiness\n",
                        "  [ 4x] easy bruising\n",
                        "  [ 4x] stiffness\n",
                        "  [ 4x] muscle cramps\n",
                        "  [ 4x] rapid heart rate\n",
                        "  [ 3x] loss of appetite\n",
                        "  [ 3x] memory loss\n",
                        "  [ 3x] unexplained weight loss\n",
                        "  [ 3x] dehydration\n",
                        "  [ 3x] bloating\n",
                        "  [ 3x] coma\n",
                        "  [ 3x] vaginal bleeding\n",
                        "  [ 3x] hoarseness\n",
                        "  [ 3x] night sweats\n",
                        "  [ 3x] delirium\n",
                        "  [ 3x] brittle nails\n",
                        "  [ 3x] bruising\n",
                        "  [ 3x] nosebleeds\n",
                        "  [ 3x] swelling of ankles\n",
                        "  [ 3x] belly pain\n",
                        "  [ 3x] fast heart rate\n",
                        "  [ 3x] loss of consciousness\n",
                        "  [ 3x] sensitivity to light\n",
                        "  [ 3x] numbness\n",
                        "  [ 3x] eye irritation\n",
                        "  [ 3x] muscle ache\n",
                        "  [ 3x] vision changes\n",
                        "  [ 3x] balance problems\n",
                        "  [ 2x] nausea and vomitting\n",
                        "  [ 2x] low-set ears\n"
                    ]
                }
            ],
            "source": [
                "# Show most common new symptoms\n",
                "new_symptom_counts = [(s, symptom_counts[s]) for s in new_symptoms]\n",
                "new_symptom_counts.sort(key=lambda x: -x[1])\n",
                "\n",
                "print(\"Most common new symptoms (top 50):\")\n",
                "print(\"-\" * 60)\n",
                "for sym, count in new_symptom_counts[:50]:\n",
                "    print(f\"  [{count:2d}x] {sym}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Symptoms appearing in >= 2 diseases: 103\n",
                        "\n",
                        "Symptoms to add:\n",
                        "  - confusion\n",
                        "  - chest pain\n",
                        "  - abdominal pain\n",
                        "  - weight loss\n",
                        "  - irritability\n",
                        "  - high blood pressure\n",
                        "  - blurred vision\n",
                        "  - loss of apetite\n",
                        "  - low blood pressure\n",
                        "  - muscle aches\n",
                        "  - bone pain\n",
                        "  - eye pain\n",
                        "  - rash\n",
                        "  - headaches\n",
                        "  - slurred speech\n",
                        "  - anxiety\n",
                        "  - tiredness\n",
                        "  - lightheadedness\n",
                        "  - stomach pain\n",
                        "  - difficulty swallowing\n",
                        "  - drowsiness\n",
                        "  - easy bruising\n",
                        "  - stiffness\n",
                        "  - muscle cramps\n",
                        "  - rapid heart rate\n",
                        "  - loss of appetite\n",
                        "  - memory loss\n",
                        "  - unexplained weight loss\n",
                        "  - dehydration\n",
                        "  - bloating\n",
                        "  - coma\n",
                        "  - vaginal bleeding\n",
                        "  - hoarseness\n",
                        "  - night sweats\n",
                        "  - delirium\n",
                        "  - brittle nails\n",
                        "  - bruising\n",
                        "  - nosebleeds\n",
                        "  - swelling of ankles\n",
                        "  - belly pain\n",
                        "  - fast heart rate\n",
                        "  - loss of consciousness\n",
                        "  - sensitivity to light\n",
                        "  - numbness\n",
                        "  - eye irritation\n",
                        "  - muscle ache\n",
                        "  - vision changes\n",
                        "  - balance problems\n",
                        "  - nausea and vomitting\n",
                        "  - low-set ears\n",
                        "  - upset stomach\n",
                        "  - poor growth\n",
                        "  - swelling\n",
                        "  - problems with balance\n",
                        "  - hair loss\n",
                        "  - losing weight\n",
                        "  - unintentional weight loss\n",
                        "  - infections\n",
                        "  - lethargy\n",
                        "  - muscle wasting\n",
                        "  - abnormal heart rhythm\n",
                        "  - frequent infections\n",
                        "  - abdominal swelling\n",
                        "  - anemia\n",
                        "  - enlarged liver\n",
                        "  - slow heart rate\n",
                        "  - dry mouth\n",
                        "  - rashes\n",
                        "  - cramping\n",
                        "  - easy bleeding\n",
                        "  - rapid breathing\n",
                        "  - swelling of legs\n",
                        "  - scoliosis\n",
                        "  - skin color changes\n",
                        "  - trouble speaking\n",
                        "  - bone ache\n",
                        "  - pain\n",
                        "  - extreme tiredness\n",
                        "  - hearing loss\n",
                        "  - paralysis\n",
                        "  - low blood sugar\n",
                        "  - hallucinations\n",
                        "  - vision problems\n",
                        "  - poor weight gain\n",
                        "  - high fever\n",
                        "  - vomitting\n",
                        "  - high blood sugar\n",
                        "  - slow growth\n",
                        "  - rapid heartbeat\n",
                        "  - dark urine\n",
                        "  - loss of coordination\n",
                        "  - heart palpitations\n",
                        "  - breathing problems\n",
                        "  - sleep problems\n",
                        "  - mood changes\n",
                        "  - low sex drive\n",
                        "  - gas\n",
                        "  - sore muscles\n",
                        "  - vision loss\n",
                        "  - diabetes\n",
                        "  - red eye\n",
                        "  - ringing in ears\n",
                        "  - dry skin\n"
                    ]
                }
            ],
            "source": [
                "# CONFIGURATION: Filter new symptoms\n",
                "# Only add symptoms that appear in at least MIN_DISEASE_COUNT diseases\n",
                "MIN_DISEASE_COUNT = 2  # Only add symptoms appearing in 5+ diseases\n",
                "\n",
                "symptoms_to_add = [s for s, count in new_symptom_counts if count >= MIN_DISEASE_COUNT]\n",
                "\n",
                "print(f\"Symptoms appearing in >= {MIN_DISEASE_COUNT} diseases: {len(symptoms_to_add)}\")\n",
                "print(\"\\nSymptoms to add:\")\n",
                "for s in symptoms_to_add:\n",
                "    print(f\"  - {s}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original vocabulary: 377 symptoms\n",
                        "Expanded vocabulary: 480 symptoms (+103)\n",
                        "\n",
                        "Saved expanded vocabulary to: c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\models\\checkpoints\\symptom_columns.json\n",
                        "NOTE: Original vocabulary file has been updated with new symptoms.\n"
                    ]
                }
            ],
            "source": [
                "# Create expanded vocabulary\n",
                "EXPANDED_VOCAB = ORIGINAL_VOCAB + symptoms_to_add\n",
                "EXPANDED_SET = set(s.lower() for s in EXPANDED_VOCAB)\n",
                "\n",
                "print(f\"Original vocabulary: {len(ORIGINAL_VOCAB)} symptoms\")\n",
                "print(f\"Expanded vocabulary: {len(EXPANDED_VOCAB)} symptoms (+{len(symptoms_to_add)})\")\n",
                "\n",
                "# Save expanded vocabulary (overwrites original)\n",
                "with open(expanded_vocab_path, 'w') as f:\n",
                "    json.dump(EXPANDED_VOCAB, f, indent=2)\n",
                "\n",
                "print(f\"\\nSaved expanded vocabulary to: {expanded_vocab_path}\")\n",
                "print(\"NOTE: Original vocabulary file has been updated with new symptoms.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Stage 1: Symptom Mapping & Synthetic Data Generation\n",
                "\n",
                "1. Map Mayo Clinic symptoms to expanded vocabulary\n",
                "2. Generate synthetic samples for diseases with <20 samples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original dataset: 222,720 rows, 667 diseases\n",
                        "\n",
                        "Diseases with <20 samples: 135\n",
                        "Total samples in rare diseases: 1,171\n"
                    ]
                }
            ],
            "source": [
                "# Load original dataset\n",
                "df = pd.read_csv(data_path)\n",
                "print(f\"Original dataset: {len(df):,} rows, {df['diseases'].nunique()} diseases\")\n",
                "\n",
                "# Get disease counts\n",
                "counts = df['diseases'].value_counts()\n",
                "rare_diseases = counts[counts < 20]\n",
                "print(f\"\\nDiseases with <20 samples: {len(rare_diseases)}\")\n",
                "print(f\"Total samples in rare diseases: {rare_diseases.sum():,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 542 disease -> category mappings\n"
                    ]
                }
            ],
            "source": [
                "# Load category mapping\n",
                "with open(category_map_path) as f:\n",
                "    category_map = json.load(f)\n",
                "\n",
                "# Create disease -> category lookup\n",
                "disease_to_category = {}\n",
                "for cat, diseases in category_map.items():\n",
                "    for d in diseases:\n",
                "        disease_to_category[d] = cat\n",
                "\n",
                "print(f\"Loaded {len(disease_to_category)} disease -> category mappings\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defined mapping and generation functions\n"
                    ]
                }
            ],
            "source": [
                "def map_symptoms_to_vocab(symptoms_list, vocab_set):\n",
                "    \"\"\"\n",
                "    Map a list of symptoms to the vocabulary.\n",
                "    Returns symptoms that exist in the vocabulary.\n",
                "    \"\"\"\n",
                "    mapped = []\n",
                "    for sym in symptoms_list:\n",
                "        sym_clean = sym.strip().lower()\n",
                "        if sym_clean in vocab_set:\n",
                "            mapped.append(sym_clean)\n",
                "    return list(set(mapped))  # Remove duplicates\n",
                "\n",
                "\n",
                "def generate_synthetic_samples(disease: str, symptoms: list, n_samples: int,\n",
                "                               all_symptoms: list, min_sym: int = 4, max_sym: int = 8) -> list:\n",
                "    \"\"\"\n",
                "    Generate synthetic samples for a disease.\n",
                "    Each sample has random 4-8 symptoms selected from the symptom list.\n",
                "    \"\"\"\n",
                "    samples = []\n",
                "    category = disease_to_category.get(disease, \"Unknown Type\")\n",
                "    \n",
                "    for _ in range(n_samples):\n",
                "        # Select random symptoms\n",
                "        n_sym = random.randint(min_sym, min(max_sym, len(symptoms)))\n",
                "        selected = random.sample(symptoms, n_sym)\n",
                "        \n",
                "        # Create row with all symptoms as 0\n",
                "        row = {col: 0 for col in all_symptoms}\n",
                "        \n",
                "        # Set selected symptoms to 1\n",
                "        for sym in selected:\n",
                "            if sym in row:\n",
                "                row[sym] = 1\n",
                "        \n",
                "        row['diseases'] = disease\n",
                "        row['disease_category'] = category\n",
                "        row['symptoms'] = \", \".join(selected)\n",
                "        \n",
                "        samples.append(row)\n",
                "    \n",
                "    return samples\n",
                "\n",
                "print(\"Defined mapping and generation functions\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Symptom mapping results:\n",
                        "  Total mayo symptoms: 1255\n",
                        "  Mapped to vocabulary: 648 (51.6%)\n",
                        "  Diseases ready for synthesis (>=4 symptoms): 78\n"
                    ]
                }
            ],
            "source": [
                "# Map symptoms for each disease in template\n",
                "disease_mapped_symptoms = {}\n",
                "mapping_stats = {'total': 0, 'mapped': 0, 'diseases_ready': 0}\n",
                "\n",
                "for disease, info in template.items():\n",
                "    mayo = info.get(\"mayo_clinic_symptoms\", [])\n",
                "    if not mayo:\n",
                "        continue\n",
                "    \n",
                "    mapped = map_symptoms_to_vocab(mayo, EXPANDED_SET)\n",
                "    mapping_stats['total'] += len(mayo)\n",
                "    mapping_stats['mapped'] += len(mapped)\n",
                "    \n",
                "    if len(mapped) >= 4:  # Minimum for synthetic generation\n",
                "        disease_mapped_symptoms[disease] = mapped\n",
                "        mapping_stats['diseases_ready'] += 1\n",
                "\n",
                "print(f\"Symptom mapping results:\")\n",
                "print(f\"  Total mayo symptoms: {mapping_stats['total']}\")\n",
                "print(f\"  Mapped to vocabulary: {mapping_stats['mapped']} ({100*mapping_stats['mapped']/mapping_stats['total']:.1f}%)\")\n",
                "print(f\"  Diseases ready for synthesis (>=4 symptoms): {mapping_stats['diseases_ready']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generated 1,224 synthetic samples for 78 diseases\n",
                        "\n",
                        "Generation details:\n",
                        "  rocky mountain spotted fever: 1 -> 25 (+24, 12 symptoms available)\n",
                        "  myocarditis: 1 -> 25 (+24, 6 symptoms available)\n",
                        "  kaposi sarcoma: 1 -> 25 (+24, 7 symptoms available)\n",
                        "  chronic ulcer: 1 -> 25 (+24, 5 symptoms available)\n",
                        "  gas gangrene: 1 -> 25 (+24, 5 symptoms available)\n",
                        "  thalassemia: 1 -> 25 (+24, 4 symptoms available)\n",
                        "  typhoid fever: 1 -> 25 (+24, 8 symptoms available)\n",
                        "  diabetic kidney disease: 2 -> 25 (+23, 6 symptoms available)\n",
                        "  rheumatic fever: 2 -> 25 (+23, 4 symptoms available)\n",
                        "  human immunodeficiency virus infection (hiv): 2 -> 25 (+23, 9 symptoms available)\n",
                        "  hashimoto thyroiditis: 2 -> 25 (+23, 10 symptoms available)\n",
                        "  sporotrichosis: 3 -> 25 (+22, 5 symptoms available)\n",
                        "  cat scratch disease: 3 -> 25 (+22, 7 symptoms available)\n",
                        "  dengue fever: 3 -> 25 (+22, 7 symptoms available)\n",
                        "  adrenal cancer: 3 -> 25 (+22, 8 symptoms available)\n",
                        "  necrotizing fasciitis: 3 -> 25 (+22, 5 symptoms available)\n",
                        "  connective tissue disorder: 3 -> 25 (+22, 7 symptoms available)\n",
                        "  myelodysplastic syndrome: 3 -> 25 (+22, 5 symptoms available)\n",
                        "  primary thrombocythemia: 3 -> 25 (+22, 8 symptoms available)\n",
                        "  hemochromatosis: 3 -> 25 (+22, 7 symptoms available)\n",
                        "  ... and 58 more diseases\n"
                    ]
                }
            ],
            "source": [
                "# Generate synthetic samples\n",
                "random.seed(42)\n",
                "TARGET_SAMPLES = 25  # Minimum samples per disease\n",
                "\n",
                "all_synthetic = []\n",
                "generation_log = []\n",
                "\n",
                "for disease, symptoms in disease_mapped_symptoms.items():\n",
                "    current_count = counts.get(disease, 0)\n",
                "    \n",
                "    if current_count >= TARGET_SAMPLES:\n",
                "        continue\n",
                "    \n",
                "    n_new = TARGET_SAMPLES - current_count\n",
                "    samples = generate_synthetic_samples(disease, symptoms, n_new, EXPANDED_VOCAB)\n",
                "    all_synthetic.extend(samples)\n",
                "    \n",
                "    generation_log.append({\n",
                "        'disease': disease,\n",
                "        'original': current_count,\n",
                "        'added': n_new,\n",
                "        'symptoms_available': len(symptoms)\n",
                "    })\n",
                "\n",
                "print(f\"Generated {len(all_synthetic):,} synthetic samples for {len(generation_log)} diseases\")\n",
                "print(\"\\nGeneration details:\")\n",
                "for log in generation_log[:20]:\n",
                "    print(f\"  {log['disease']}: {log['original']} -> {log['original'] + log['added']} (+{log['added']}, {log['symptoms_available']} symptoms available)\")\n",
                "if len(generation_log) > 20:\n",
                "    print(f\"  ... and {len(generation_log) - 20} more diseases\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Expanded original dataset to 482 columns\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\henry\\AppData\\Local\\Temp\\ipykernel_18816\\2459726059.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[new_sym] = 0\n",
                        "C:\\Users\\henry\\AppData\\Local\\Temp\\ipykernel_18816\\2459726059.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[new_sym] = 0\n",
                        "C:\\Users\\henry\\AppData\\Local\\Temp\\ipykernel_18816\\2459726059.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[new_sym] = 0\n",
                        "C:\\Users\\henry\\AppData\\Local\\Temp\\ipykernel_18816\\2459726059.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[new_sym] = 0\n",
                        "C:\\Users\\henry\\AppData\\Local\\Temp\\ipykernel_18816\\2459726059.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[new_sym] = 0\n"
                    ]
                }
            ],
            "source": [
                "# Create expanded base dataset with new symptom columns\n",
                "# Original columns + new symptom columns (all 0s for original rows)\n",
                "\n",
                "# Add new symptom columns to original data\n",
                "for new_sym in symptoms_to_add:\n",
                "    if new_sym not in df.columns:\n",
                "        df[new_sym] = 0\n",
                "\n",
                "print(f\"Expanded original dataset to {len(df.columns)} columns\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original samples: 222,720\n",
                        "Synthetic samples: 1,224\n",
                        "Total augmented: 223,944\n"
                    ]
                }
            ],
            "source": [
                "# Combine original + synthetic\n",
                "if all_synthetic:\n",
                "    df_synthetic = pd.DataFrame(all_synthetic)\n",
                "    \n",
                "    # Ensure same columns in same order\n",
                "    for col in df.columns:\n",
                "        if col not in df_synthetic.columns:\n",
                "            df_synthetic[col] = 0\n",
                "    \n",
                "    df_synthetic = df_synthetic[df.columns]\n",
                "    \n",
                "    df_augmented = pd.concat([df, df_synthetic], ignore_index=True)\n",
                "    \n",
                "    print(f\"Original samples: {len(df):,}\")\n",
                "    print(f\"Synthetic samples: {len(df_synthetic):,}\")\n",
                "    print(f\"Total augmented: {len(df_augmented):,}\")\n",
                "else:\n",
                "    df_augmented = df\n",
                "    print(\"No synthetic samples generated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Before augmentation: 135 diseases with <20 samples\n",
                        "After augmentation: 57 diseases with <20 samples\n",
                        "\n",
                        "Diseases still below 20 samples:\n",
                        "  19  otosclerosis\n",
                        "  18  cyst of the eyelid\n",
                        "  14  fibrocystic breast disease\n",
                        "  14  pneumoconiosis\n",
                        "  13  hpv\n",
                        "  13  congenital malformation syndrome\n",
                        "  13  factitious disorder\n",
                        "  12  raynaud disease\n",
                        "  11  myoclonus\n",
                        "  11  birth trauma\n",
                        "  11  zenker diverticulum\n",
                        "  11  galactorrhea of unknown cause\n",
                        "  10  vesicoureteral reflux\n",
                        "  10  decubitus ulcer\n",
                        "  10  testicular cancer\n",
                        "  10  reactive arthritis\n",
                        "  10  optic neuritis\n",
                        "  10  avascular necrosis\n",
                        "  10  granuloma inguinale\n",
                        "   9  placenta previa\n",
                        "   9  insulin overdose\n",
                        "   9  hemarthrosis\n",
                        "   9  thyroid cancer\n",
                        "   9  aphakia\n",
                        "   9  poisoning due to opioids\n",
                        "   9  lichen planus\n",
                        "   9  hammer toe\n",
                        "   9  vacterl syndrome\n",
                        "   8  hypercholesterolemia\n",
                        "   8  spinocerebellar ataxia\n",
                        "   7  pemphigus\n",
                        "   7  fetal alcohol syndrome\n",
                        "   7  omphalitis\n",
                        "   6  edward syndrome\n",
                        "   6  breast cancer\n",
                        "   6  pinguecula\n",
                        "   6  priapism\n",
                        "   6  blepharospasm\n",
                        "   6  tuberous sclerosis\n",
                        "   6  g6pd enzyme deficiency\n",
                        "   6  vulvar cancer\n",
                        "   5  uterine cancer\n",
                        "   5  pelvic fistula\n",
                        "   5  vitamin a deficiency\n",
                        "   5  spherocytosis\n",
                        "   5  cryptorchidism\n",
                        "   4  oral leukoplakia\n",
                        "   4  intussusception\n",
                        "   3  esophageal varices\n",
                        "   3  hyperlipidemia\n",
                        "   3  obesity\n",
                        "   2  carcinoid syndrome\n",
                        "   1  turner syndrome\n",
                        "   1  hypergammaglobulinemia\n",
                        "   1  huntington disease\n",
                        "   1  high blood pressure\n",
                        "   1  diabetes\n"
                    ]
                }
            ],
            "source": [
                "# Verify rare disease counts improved\n",
                "new_counts = df_augmented['diseases'].value_counts()\n",
                "new_rare = new_counts[new_counts < 20]\n",
                "\n",
                "print(f\"Before augmentation: {len(rare_diseases)} diseases with <20 samples\")\n",
                "print(f\"After augmentation: {len(new_rare)} diseases with <20 samples\")\n",
                "print(f\"\\nDiseases still below 20 samples:\")\n",
                "for d, c in new_rare.items():\n",
                "    print(f\"  {c:2d}  {d}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved dataset WITHOUT demographics:\n",
                        "  Path: c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\processed\\symptoms\\symptoms_augmented_no_demographics.csv\n",
                        "  Size: 214.0 MB\n",
                        "  Rows: 223,944\n",
                        "  Columns: 482\n"
                    ]
                }
            ],
            "source": [
                "# Save dataset WITHOUT demographics\n",
                "df_augmented.to_csv(output_no_demo_path, index=False)\n",
                "\n",
                "print(f\"Saved dataset WITHOUT demographics:\")\n",
                "print(f\"  Path: {output_no_demo_path}\")\n",
                "print(f\"  Size: {output_no_demo_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
                "print(f\"  Rows: {len(df_augmented):,}\")\n",
                "print(f\"  Columns: {len(df_augmented.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Stage 2: Add Demographics (Age, Sex)\n",
                "\n",
                "Using merged demographics from ChatGPT + synthetic rules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded demographics for 667 diseases\n",
                        "\n",
                        "Demographic coverage:\n",
                        "  Total diseases in dataset: 667\n",
                        "  Covered by demographics: 667 (100.0%)\n",
                        "  Missing (will use defaults): 0\n"
                    ]
                }
            ],
            "source": [
                "# Load demographics\n",
                "with open(demographics_path) as f:\n",
                "    demographics = json.load(f)\n",
                "\n",
                "print(f\"Loaded demographics for {len(demographics)} diseases\")\n",
                "\n",
                "# Check coverage\n",
                "all_diseases = set(df_augmented['diseases'].unique())\n",
                "demo_diseases = set(demographics.keys())\n",
                "covered = all_diseases & demo_diseases\n",
                "missing = all_diseases - demo_diseases\n",
                "\n",
                "print(f\"\\nDemographic coverage:\")\n",
                "print(f\"  Total diseases in dataset: {len(all_diseases)}\")\n",
                "print(f\"  Covered by demographics: {len(covered)} ({100*len(covered)/len(all_diseases):.1f}%)\")\n",
                "print(f\"  Missing (will use defaults): {len(missing)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defined demographic sampling functions\n"
                    ]
                }
            ],
            "source": [
                "# Default demographics for missing diseases\n",
                "DEFAULT_DEMO = {\n",
                "    \"age_min\": 10,\n",
                "    \"age_max\": 80,\n",
                "    \"age_peak\": 45,\n",
                "    \"male_pct\": 50\n",
                "}\n",
                "\n",
                "def sample_age(demo: dict) -> int:\n",
                "    \"\"\"Sample age from triangular distribution.\"\"\"\n",
                "    age_min = demo.get('age_min', 10)\n",
                "    age_max = demo.get('age_max', 80)\n",
                "    age_peak = demo.get('age_peak', 45)\n",
                "    \n",
                "    # Handle edge cases\n",
                "    if age_min == age_max:\n",
                "        return int(age_min)\n",
                "    \n",
                "    age_peak = max(age_min, min(age_peak, age_max))\n",
                "    \n",
                "    if age_min == age_peak or age_peak == age_max:\n",
                "        age = np.random.uniform(age_min, age_max)\n",
                "    else:\n",
                "        age = np.random.triangular(age_min, age_peak, age_max)\n",
                "    \n",
                "    return int(np.clip(age, 0, 100))\n",
                "\n",
                "\n",
                "def sample_sex(demo: dict) -> str:\n",
                "    \"\"\"Sample sex from Bernoulli distribution.\"\"\"\n",
                "    male_pct = demo.get('male_pct', 50)\n",
                "    return 'M' if np.random.random() * 100 < male_pct else 'F'\n",
                "\n",
                "print(\"Defined demographic sampling functions\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processed 0 rows...\n",
                        "Processed 50,000 rows...\n",
                        "Processed 100,000 rows...\n",
                        "Processed 150,000 rows...\n",
                        "Processed 200,000 rows...\n",
                        "\n",
                        "Generated demographics for 223,944 rows\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\henry\\AppData\\Local\\Temp\\ipykernel_18816\\1234163315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df_augmented['age'] = ages\n",
                        "C:\\Users\\henry\\AppData\\Local\\Temp\\ipykernel_18816\\1234163315.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df_augmented['sex'] = sexes\n"
                    ]
                }
            ],
            "source": [
                "# Generate demographics for all rows\n",
                "np.random.seed(42)\n",
                "ages = []\n",
                "sexes = []\n",
                "\n",
                "for idx, row in df_augmented.iterrows():\n",
                "    disease = row['diseases']\n",
                "    demo = demographics.get(disease, DEFAULT_DEMO)\n",
                "    \n",
                "    ages.append(sample_age(demo))\n",
                "    sexes.append(sample_sex(demo))\n",
                "    \n",
                "    if idx % 50000 == 0:\n",
                "        print(f\"Processed {idx:,} rows...\")\n",
                "\n",
                "df_augmented['age'] = ages\n",
                "df_augmented['sex'] = sexes\n",
                "\n",
                "print(f\"\\nGenerated demographics for {len(df_augmented):,} rows\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Demographics Summary:\n",
                        "==================================================\n",
                        "Age: min=0, max=98, mean=43.3\n",
                        "Sex: 47.9% male, 52.1% female\n",
                        "\n",
                        "sex\n",
                        "F    116580\n",
                        "M    107364\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Summary statistics\n",
                "print(\"Demographics Summary:\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Age: min={df_augmented['age'].min()}, max={df_augmented['age'].max()}, mean={df_augmented['age'].mean():.1f}\")\n",
                "print(f\"Sex: {(df_augmented['sex'] == 'M').mean() * 100:.1f}% male, {(df_augmented['sex'] == 'F').mean() * 100:.1f}% female\")\n",
                "print(f\"\\n{df_augmented['sex'].value_counts()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Verification - Sample diseases:\n",
                        "================================================================================\n",
                        "prostate cancer           Age:  71.7 (exp:  70), Male: 100.0% (exp: 100%), n=135\n",
                        "preeclampsia              Age:  30.4 (exp:  30), Male:   0.0% (exp:   0%), n=217\n",
                        "migraine                  Age:  30.8 (exp:  30), Male:  26.7% (exp:  30%), n=221\n",
                        "pyloric stenosis          Age:   0.0 (exp:   0), Male:  80.0% (exp:  80%), n=25\n",
                        "diabetes                  Age:  70.0 (exp:  55), Male: 100.0% (exp:  52%), n=1\n"
                    ]
                }
            ],
            "source": [
                "# Verify key diseases\n",
                "print(\"Verification - Sample diseases:\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "verify_diseases = [\"prostate cancer\", \"preeclampsia\", \"migraine\", \"pyloric stenosis\", \"diabetes\"]\n",
                "\n",
                "for disease in verify_diseases:\n",
                "    subset = df_augmented[df_augmented['diseases'] == disease]\n",
                "    if len(subset) > 0:\n",
                "        male_pct = (subset['sex'] == 'M').mean() * 100\n",
                "        mean_age = subset['age'].mean()\n",
                "        expected = demographics.get(disease, DEFAULT_DEMO)\n",
                "        \n",
                "        print(f\"{disease:25} Age: {mean_age:5.1f} (exp: {expected.get('age_peak', '?'):>3}), \"\n",
                "              f\"Male: {male_pct:5.1f}% (exp: {expected.get('male_pct', '?'):>3}%), \"\n",
                "              f\"n={len(subset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Reordered columns: 484 total\n",
                        "First 10: ['diseases', 'disease_category', 'age', 'sex', 'anxiety and nervousness', 'depression', 'shortness of breath', 'depressive or psychotic symptoms', 'sharp chest pain', 'dizziness']\n"
                    ]
                }
            ],
            "source": [
                "# Reorder columns: diseases, category, age, sex, then symptoms\n",
                "cols = df_augmented.columns.tolist()\n",
                "\n",
                "# Move key columns to front\n",
                "key_cols = ['diseases', 'disease_category', 'age', 'sex']\n",
                "symptom_cols = [c for c in cols if c not in key_cols + ['symptoms']]\n",
                "final_order = key_cols + symptom_cols + ['symptoms']\n",
                "\n",
                "# Only include columns that exist\n",
                "final_order = [c for c in final_order if c in df_augmented.columns]\n",
                "\n",
                "df_final = df_augmented[final_order]\n",
                "print(f\"Reordered columns: {len(df_final.columns)} total\")\n",
                "print(f\"First 10: {df_final.columns[:10].tolist()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved dataset WITH demographics:\n",
                        "  Path: c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\processed\\symptoms\\symptoms_augmented_with_demographics.csv\n",
                        "  Size: 215.0 MB\n",
                        "  Rows: 223,944\n",
                        "  Columns: 484\n"
                    ]
                }
            ],
            "source": [
                "# Save dataset WITH demographics\n",
                "df_final.to_csv(output_with_demo_path, index=False)\n",
                "\n",
                "print(f\"Saved dataset WITH demographics:\")\n",
                "print(f\"  Path: {output_with_demo_path}\")\n",
                "print(f\"  Size: {output_with_demo_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
                "print(f\"  Rows: {len(df_final):,}\")\n",
                "print(f\"  Columns: {len(df_final.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Summary\n",
                "\n",
                "## Output Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================================================================\n",
                        "DATA AUGMENTATION COMPLETE\n",
                        "================================================================================\n",
                        "\n",
                        "1. EXPANDED VOCABULARY:\n",
                        "   c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\models\\checkpoints\\symptom_columns.json\n",
                        "   Original: 377 symptoms\n",
                        "   Expanded: 480 symptoms (+103)\n",
                        "\n",
                        "2. DATASET WITHOUT DEMOGRAPHICS:\n",
                        "   c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\processed\\symptoms\\symptoms_augmented_no_demographics.csv\n",
                        "   Rows: 223,944, Columns: 482\n",
                        "   Size: 214.0 MB\n",
                        "\n",
                        "3. DATASET WITH DEMOGRAPHICS:\n",
                        "   c:\\Users\\henry\\Desktop\\Programming\\Python\\Multimodal_Diagnosis\\data\\processed\\symptoms\\symptoms_augmented_with_demographics.csv\n",
                        "   Rows: 223,944, Columns: 484\n",
                        "   Size: 215.0 MB\n",
                        "   Includes: age, sex columns\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\" * 80)\n",
                "print(\"DATA AUGMENTATION COMPLETE\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "print(\"\\n1. EXPANDED VOCABULARY:\")\n",
                "print(f\"   {expanded_vocab_path}\")\n",
                "print(f\"   Original: {len(ORIGINAL_VOCAB)} symptoms\")\n",
                "print(f\"   Expanded: {len(EXPANDED_VOCAB)} symptoms (+{len(symptoms_to_add)})\")\n",
                "\n",
                "print(\"\\n2. DATASET WITHOUT DEMOGRAPHICS:\")\n",
                "print(f\"   {output_no_demo_path}\")\n",
                "if output_no_demo_path.exists():\n",
                "    df_check = pd.read_csv(output_no_demo_path, nrows=1)\n",
                "    print(f\"   Rows: {len(df_augmented):,}, Columns: {len(df_check.columns)}\")\n",
                "    print(f\"   Size: {output_no_demo_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
                "\n",
                "print(\"\\n3. DATASET WITH DEMOGRAPHICS:\")\n",
                "print(f\"   {output_with_demo_path}\")\n",
                "if output_with_demo_path.exists():\n",
                "    df_check = pd.read_csv(output_with_demo_path, nrows=1)\n",
                "    print(f\"   Rows: {len(df_final):,}, Columns: {len(df_check.columns)}\")\n",
                "    print(f\"   Size: {output_with_demo_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
                "    print(f\"   Includes: age, sex columns\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Documentation for Research Paper\n",
                "\n",
                "> **Data Augmentation Pipeline**\n",
                ">\n",
                "> **Stage 0 - Vocabulary Expansion:**\n",
                "> 1. Collected symptom lists from Mayo Clinic and Cleveland Clinic for 135 rare diseases\n",
                "> 2. Identified symptoms appearing in >=5 diseases not in original vocabulary\n",
                "> 3. Expanded vocabulary from 377 to N symptoms (updated in place)\n",
                ">\n",
                "> **Stage 1 - Synthetic Symptom Data:**\n",
                "> 1. Mapped Mayo Clinic symptoms to expanded vocabulary\n",
                "> 2. For diseases with <20 training samples, generated synthetic samples\n",
                "> 3. Each synthetic sample: random 4-8 symptom subset from disease's symptom profile\n",
                "> 4. Increased rare disease representation to minimum 25 samples per disease\n",
                ">\n",
                "> **Stage 2 - Demographic Variables (Age/Sex):**\n",
                "> 1. Collected epidemiological demographics via GPT-4 queries\n",
                "> 2. Applied category-level defaults with keyword-based overrides for sex-specific diseases\n",
                "> 3. Age sampled from triangular distribution (min, peak, max)\n",
                "> 4. Sex sampled from Bernoulli distribution based on disease-specific male percentage\n",
                ">\n",
                "> Two output datasets were created:\n",
                "> - `symptoms_augmented_no_demographics.csv`: For symptom-only models\n",
                "> - `symptoms_augmented_with_demographics.csv`: For multimodal models incorporating age/sex"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "multimodal",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
